{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d24680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def compile_keyword_patterns(keywords):\n",
    "    return [re.compile(rf\"\\b{re.escape(kw)}\\b\", re.IGNORECASE) for kw in keywords]\n",
    "\n",
    "KEYWORDS = [\n",
    "    \"automated processing\",\n",
    "    \"profiling\",\n",
    "    \"artificial intelligence\",\n",
    "    \"ai\",\n",
    "    \"machine learning\",\n",
    "    \"deep learning\",\n",
    "    \"neural network\",\n",
    "    \"algorithm\",\n",
    "    \"intelligent system\",\n",
    "    \"intelligent systems\",\n",
    "    \"automated system\",\n",
    "    \"automated systems\",\n",
    "    \"decision-making\",\n",
    "    \"automated decision\",\n",
    "    \"automated decision-making\",\n",
    "    \"autonomous system\",\n",
    "    \"autonomous systems\",\n",
    "    \"predictive model\",\n",
    "    \"predictive analytics\",\n",
    "    \"computer vision\",\n",
    "    \"natural language processing\",\n",
    "    \"nlp\",\n",
    "    \"data-driven\",\n",
    "    \"learning system\",\n",
    "    \"self-learning\",\n",
    "    \"self-learning system\",\n",
    "    \"pattern recognition\",\n",
    "    \"classification model\",\n",
    "    \"generative model\",\n",
    "    \"chatbot\",\n",
    "    \"large language model\",\n",
    "    \"language model\",\n",
    "    \"reinforcement learning\",\n",
    "    \"unsupervised learning\",\n",
    "    \"supervised learning\",\n",
    "    \"training data\",\n",
    "    \"training dataset\",\n",
    "    \"ai system\",\n",
    "    \"ai-based\",\n",
    "    \"ml-based\",\n",
    "    \"intelligent automation\",\n",
    "    \"cognitive computing\",\n",
    "    \"robotic process automation\",\n",
    "    \"rpa\",\n",
    "    \"digital agent\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compiled_patterns = compile_keyword_patterns(KEYWORDS)\n",
    "\n",
    "def contains_keywords(text):\n",
    "    matched = [pat.pattern.strip(r\"\\b\").lower() for pat in compiled_patterns if pat.search(text)]\n",
    "    return bool(matched), matched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "BASE_URL = \"https://api.anthropic.com/v1/messages\"\n",
    "MODEL_NAME = \"claude-3-sonnet-20240229\"\n",
    "MAX_RETRIES = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_claude(prompt):\n",
    "    retries = 0\n",
    "    while retries < MAX_RETRIES:\n",
    "        try:\n",
    "            headers = {\n",
    "                \"x-api-key\": API_KEY,\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"anthropic-version\": \"2023-06-01\"\n",
    "            }\n",
    "\n",
    "            data = {\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_tokens\": 50,\n",
    "                \"temperature\": 0,\n",
    "            }\n",
    "\n",
    "            response = requests.post(BASE_URL, headers=headers, data=json.dumps(data))\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                for item in result.get(\"content\", []):\n",
    "                    if item.get(\"type\") == \"text\":\n",
    "                        return item.get(\"text\", \"\").strip()\n",
    "            else:\n",
    "                print(f\"Error {response.status_code}: {response.text}\")\n",
    "                retries += 1\n",
    "                time.sleep(2 ** retries + random.uniform(0, 1))\n",
    "        except Exception as e:\n",
    "            print(f\"Request error: {e}\")\n",
    "            retries += 1\n",
    "            time.sleep(2 ** retries + random.uniform(0, 1))\n",
    "\n",
    "    return \"Error: Failed after retries\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def moving_window(paragraphs, window_size=2):\n",
    "    for i in range(len(paragraphs) - window_size + 1):\n",
    "        yield i, paragraphs[i:i+window_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scan_for_ai_mentions(paragraph_dir, window_size=2, output_file=\"ai_detection_results.json\"):\n",
    "    paragraphs = []\n",
    "\n",
    "    # Load all .txt segments (assumes ordered filenames)\n",
    "    for file_path in sorted(Path(paragraph_dir).glob(\"*.txt\")):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            paragraphs.append(f.read().strip())\n",
    "\n",
    "    results = []\n",
    "    for index, window in moving_window(paragraphs, window_size):\n",
    "        combined_text = \"\\n\\n\".join(window)\n",
    "        is_match, matched_keywords = contains_keywords(combined_text)\n",
    "        if is_match:\n",
    "            answer = f\"Yes (keyword match: {', '.join(matched_keywords)})\"\n",
    "        else:\n",
    "            prompt = (\n",
    "                \"Does the following text mention or relate to artificial intelligence (AI)? \"\n",
    "                \"Answer 'Yes' or 'No' only. Don't say anything but 'Yes' or 'No' don't add any text after.\\n\\n\"\n",
    "                f\"Text:\\n{combined_text}\"\n",
    "            )\n",
    "            answer = ask_claude(prompt)\n",
    "        results.append({\n",
    "            \"start_index\": index,\n",
    "            \"window\": window,\n",
    "            \"response\": answer\n",
    "        })\n",
    "        print(f\"Window {index}: {answer}\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_f:\n",
    "        json.dump(results, out_f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    \n",
    "    yes_results = [r for r in results if r[\"response\"].strip().lower().startswith(\"yes\")]\n",
    "\n",
    "    yes_output_file = output_file.replace(\".json\", \"_only_yes.json\")\n",
    "    with open(yes_output_file, 'w', encoding='utf-8') as yes_f:\n",
    "        json.dump(yes_results, yes_f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nâœ… Saved {len(yes_results)} 'Yes' results to {yes_output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fileName = \"synthetic_paragraphs_for_test2\"\n",
    "    segment_dir = \"./\" + fileName\n",
    "    scan_for_ai_mentions(segment_dir, window_size=1, output_file=\"isAI/\" + fileName + \"_ai_detection_results.json\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     base_dir = Path(\"./fichiers segmentÃ©s\")\n",
    "#     for segment_dir in base_dir.iterdir():\n",
    "#         if segment_dir.is_dir():\n",
    "#             print(f\"\\nðŸ” Scanning: {segment_dir}\")\n",
    "#             relative_name = segment_dir.relative_to(\"fichiers segmentÃ©s\")\n",
    "#             output_json = \"./isAI/\" + f\"{relative_name}.json\"\n",
    "#             print(f\"Output file: {output_json}\")\n",
    "#             scan_for_ai_mentions(segment_dir, window_size=2, output_file=output_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecabb77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
