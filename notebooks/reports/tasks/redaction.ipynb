{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e03ed0e",
   "metadata": {},
   "source": [
    "## Prec & Recall on synth contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71def97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_programs.utils import load\n",
    "from pathlib import Path\n",
    "root_dir = Path(\"../../../\")\n",
    "results_dir = root_dir / \"results/redaction/synth/\"\n",
    "results_file = results_dir / \"eval_n10_seed42_gemini.pkl\"\n",
    "results = load(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc8649b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: 1 call, 1 prompt, Document: synth_contract_000, P&R naive: 0.53, 0.77, P&R red: 0.63, 0.77\n",
      "Method: 1 call, 1 prompt, Document: synth_contract_001, P&R naive: 0.64, 0.82, P&R red: 0.64, 0.82\n",
      "Method: 1 call, 1 prompt, Document: synth_contract_002, P&R naive: 0.69, 0.75, P&R red: 0.69, 0.75\n",
      "Method: 1 call, 1 prompt, Document: synth_contract_003, P&R naive: 0.68, 0.81, P&R red: 0.68, 0.90\n",
      "Method: 1 call, 1 prompt, Document: synth_contract_004, P&R naive: 0.67, 0.73, P&R red: 0.75, 0.82\n",
      "Method: 1 call, 1 prompt, Document: synth_contract_005, P&R naive: 0.42, 0.80, P&R red: 0.53, 0.90\n",
      "Method: 1 call, 1 prompt, Document: synth_contract_006, P&R naive: 0.48, 0.83, P&R red: 0.62, 0.83\n",
      "Method: 1 call, 1 prompt, Document: synth_contract_007, P&R naive: 0.64, 0.60, P&R red: 0.64, 0.73\n",
      "Method: 1 call, 1 prompt, Document: synth_contract_008, P&R naive: 0.79, 0.79, P&R red: 0.79, 0.79\n",
      "Method: 1 call, 1 prompt, Document: synth_contract_009, P&R naive: 0.61, 0.92, P&R red: 0.67, 0.92\n",
      "Method: 1 call, M prompts, Document: synth_contract_000, P&R naive: 0.76, 1.00, P&R red: 0.76, 1.00\n",
      "Method: 1 call, M prompts, Document: synth_contract_001, P&R naive: 1.00, 0.91, P&R red: 1.00, 0.91\n",
      "Method: 1 call, M prompts, Document: synth_contract_002, P&R naive: 0.92, 0.92, P&R red: 0.92, 0.92\n",
      "Method: 1 call, M prompts, Document: synth_contract_003, P&R naive: 0.76, 0.90, P&R red: 0.76, 0.95\n",
      "Method: 1 call, M prompts, Document: synth_contract_004, P&R naive: 0.85, 1.00, P&R red: 0.85, 1.00\n",
      "Method: 1 call, M prompts, Document: synth_contract_005, P&R naive: 0.59, 1.00, P&R red: 0.65, 1.00\n",
      "Method: 1 call, M prompts, Document: synth_contract_006, P&R naive: 0.86, 1.00, P&R red: 0.86, 1.00\n",
      "Method: 1 call, M prompts, Document: synth_contract_007, P&R naive: 1.00, 0.93, P&R red: 1.00, 0.93\n",
      "Method: 1 call, M prompts, Document: synth_contract_008, P&R naive: 0.93, 0.93, P&R red: 0.93, 0.93\n",
      "Method: 1 call, M prompts, Document: synth_contract_009, P&R naive: 0.61, 0.92, P&R red: 0.72, 0.92\n",
      "Method: N calls, M prompts, OR, Document: synth_contract_000, P&R naive: 0.76, 1.00, P&R red: 0.76, 1.00\n",
      "Method: N calls, M prompts, OR, Document: synth_contract_001, P&R naive: 1.00, 0.91, P&R red: 1.00, 0.91\n",
      "Method: N calls, M prompts, OR, Document: synth_contract_002, P&R naive: 0.92, 0.92, P&R red: 0.92, 0.92\n",
      "Method: N calls, M prompts, OR, Document: synth_contract_003, P&R naive: 0.76, 0.90, P&R red: 0.76, 0.95\n",
      "Method: N calls, M prompts, OR, Document: synth_contract_004, P&R naive: 0.85, 1.00, P&R red: 0.85, 1.00\n",
      "Method: N calls, M prompts, OR, Document: synth_contract_005, P&R naive: 0.59, 1.00, P&R red: 0.65, 1.00\n",
      "Method: N calls, M prompts, OR, Document: synth_contract_006, P&R naive: 0.86, 1.00, P&R red: 0.86, 1.00\n",
      "Method: N calls, M prompts, OR, Document: synth_contract_007, P&R naive: 1.00, 0.93, P&R red: 1.00, 0.93\n",
      "Method: N calls, M prompts, OR, Document: synth_contract_008, P&R naive: 0.93, 0.93, P&R red: 0.93, 0.93\n",
      "Method: N calls, M prompts, OR, Document: synth_contract_009, P&R naive: 0.61, 0.92, P&R red: 0.72, 0.92\n",
      "Method: N calls, M prompts, AND, Document: synth_contract_000, P&R naive: 0.76, 1.00, P&R red: 0.76, 1.00\n",
      "Method: N calls, M prompts, AND, Document: synth_contract_001, P&R naive: 1.00, 0.91, P&R red: 1.00, 0.91\n",
      "Method: N calls, M prompts, AND, Document: synth_contract_002, P&R naive: 0.92, 0.92, P&R red: 0.92, 0.92\n",
      "Method: N calls, M prompts, AND, Document: synth_contract_003, P&R naive: 0.76, 0.90, P&R red: 0.76, 0.95\n",
      "Method: N calls, M prompts, AND, Document: synth_contract_004, P&R naive: 0.85, 1.00, P&R red: 0.85, 1.00\n",
      "Method: N calls, M prompts, AND, Document: synth_contract_005, P&R naive: 0.59, 1.00, P&R red: 0.65, 1.00\n",
      "Method: N calls, M prompts, AND, Document: synth_contract_006, P&R naive: 0.86, 1.00, P&R red: 0.86, 1.00\n",
      "Method: N calls, M prompts, AND, Document: synth_contract_007, P&R naive: 1.00, 0.93, P&R red: 1.00, 0.93\n",
      "Method: N calls, M prompts, AND, Document: synth_contract_008, P&R naive: 0.93, 0.93, P&R red: 0.93, 0.93\n",
      "Method: N calls, M prompts, AND, Document: synth_contract_009, P&R naive: 0.92, 0.92, P&R red: 0.92, 0.92\n"
     ]
    }
   ],
   "source": [
    "for method_key in results:\n",
    "    for doc_key in results[method_key]:\n",
    "        naive_precision = results[method_key][doc_key][\"naive_precision\"]\n",
    "        naive_recall = results[method_key][doc_key][\"naive_recall\"]\n",
    "        red_precision = results[method_key][doc_key][\"red_precision\"]\n",
    "        red_recall = results[method_key][doc_key][\"red_recall\"]\n",
    "        print(f\"Method: {method_key}, Document: {doc_key}, P&R naive: {naive_precision:.2f}, {naive_recall:.2f}, P&R red: {red_precision:.2f}, {red_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d445e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: 1 call, 1 prompt\n",
      "  Avg Naive Precision: 0.61\n",
      "  Avg Naive Recall: 0.78\n",
      "  Avg Redaction Precision: 0.66\n",
      "  Avg Redaction Recall: 0.82\n",
      "Method: 1 call, M prompts\n",
      "  Avg Naive Precision: 0.83\n",
      "  Avg Naive Recall: 0.95\n",
      "  Avg Redaction Precision: 0.84\n",
      "  Avg Redaction Recall: 0.96\n",
      "Method: N calls, M prompts, OR\n",
      "  Avg Naive Precision: 0.83\n",
      "  Avg Naive Recall: 0.95\n",
      "  Avg Redaction Precision: 0.84\n",
      "  Avg Redaction Recall: 0.96\n",
      "Method: N calls, M prompts, AND\n",
      "  Avg Naive Precision: 0.86\n",
      "  Avg Naive Recall: 0.95\n",
      "  Avg Redaction Precision: 0.86\n",
      "  Avg Redaction Recall: 0.96\n"
     ]
    }
   ],
   "source": [
    "average_metrics = {}\n",
    "\n",
    "for method_key in results:\n",
    "    total_naive_precision = 0\n",
    "    total_naive_recall = 0\n",
    "    total_red_precision = 0\n",
    "    total_red_recall = 0\n",
    "    doc_count = len(results[method_key])\n",
    "    \n",
    "    for doc_key in results[method_key]:\n",
    "        total_naive_precision += results[method_key][doc_key][\"naive_precision\"]\n",
    "        total_naive_recall += results[method_key][doc_key][\"naive_recall\"]\n",
    "        total_red_precision += results[method_key][doc_key][\"red_precision\"]\n",
    "        total_red_recall += results[method_key][doc_key][\"red_recall\"]\n",
    "    \n",
    "    average_metrics[method_key] = {\n",
    "        \"avg_naive_precision\": total_naive_precision / doc_count,\n",
    "        \"avg_naive_recall\": total_naive_recall / doc_count,\n",
    "        \"avg_red_precision\": total_red_precision / doc_count,\n",
    "        \"avg_red_recall\": total_red_recall / doc_count,\n",
    "    }\n",
    "\n",
    "for method, metrics in average_metrics.items():\n",
    "    print(f\"Method: {method}\")\n",
    "    print(f\"  Avg Naive Precision: {metrics['avg_naive_precision']:.2f}\")\n",
    "    print(f\"  Avg Naive Recall: {metrics['avg_naive_recall']:.2f}\")\n",
    "    print(f\"  Avg Redaction Precision: {metrics['avg_red_precision']:.2f}\")\n",
    "    print(f\"  Avg Redaction Recall: {metrics['avg_red_recall']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.12-hack-dsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
